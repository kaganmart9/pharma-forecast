{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55012ad8",
   "metadata": {},
   "source": [
    "<h1 align=\"center\"> Model Optimization (Random Forest) — Objective & Plan </h1>\n",
    "\n",
    "## Objective\n",
    "Improve forecast accuracy (lower RMSE/MAE/MAPE) for weekly sales by tuning a Random Forest model and standardizing a reproducible workflow.\n",
    "\n",
    "## Scope\n",
    "- Targets: `N02BE`, `M01AB`\n",
    "- Features: safe feature set (lags + calendar)\n",
    "- Validation: time-aware CV (`TimeSeriesSplit`)\n",
    "- Comparison: before vs. after tuning (hold-out test)\n",
    "\n",
    "## Metrics\n",
    "- Primary: RMSE\n",
    "- Secondary: MAE, MAPE\n",
    "\n",
    "## Plan\n",
    "1. Load processed data and reproduce the same train/test split.\n",
    "2. Prepare **two feature set variants**:\n",
    "   - Full-safe (all lag + calendar)\n",
    "   - Reduced-safe (drop weak calendar + far/low-utility lags)\n",
    "3. Set up `TimeSeriesSplit` with consistent folds.\n",
    "4. Run hyperparameter search for Random Forest (Randomized → focused Grid).\n",
    "5. Retrain best configuration on full train; evaluate on test.\n",
    "6. (Optional) Evaluate Reduced-safe set similarly.\n",
    "7. Save artifacts (best params, metrics) and summarize improvements.\n",
    "\n",
    "## Acceptance\n",
    "- Same time split as earlier notebooks.\n",
    "- Clear “before vs. after” metrics table for both targets.\n",
    "- Artifacts saved under `../results/` and `../models/`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e7ed67",
   "metadata": {},
   "source": [
    "## 1) Data & Feature Set Preparation\n",
    "\n",
    "We reproduce the same 80/20 chronological split and build two feature sets:\n",
    "\n",
    "- **Full-safe:** all lag features + calendar (`weekofyear`, `month`, `quarter`, `year`).\n",
    "- **Reduced-safe:** union of top features from permutation-importance (per target) + minimal calendar.  \n",
    "  Rationale: keep only features with proven predictive contribution on the test set and drop weak calendar flags.\n",
    "\n",
    "Sanity checks:\n",
    "- No current-week base columns\n",
    "- No rolling features\n",
    "- Same split dates as previous notebooks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3119a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date range: 2014-06-15 00:00:00 → 2019-10-13 00:00:00\n",
      "Train: 2014-06-15 00:00:00 → 2018-09-16 00:00:00  |  Test: 2018-09-23 00:00:00 → 2019-10-13 00:00:00\n",
      "\n",
      "[Full-safe] Feature count: 52\n",
      "Example features: ['M01AB_lag1', 'M01AB_lag2', 'M01AB_lag3', 'M01AB_lag4', 'M01AB_lag8', 'M01AB_lag12', 'M01AE_lag1', 'M01AE_lag2', 'M01AE_lag3', 'M01AE_lag4']\n",
      "\n",
      "[Reduced-safe] Feature count: 35\n",
      "Example features: ['M01AB_lag2', 'M01AE_lag8', 'N02BA_lag1', 'N02BA_lag12', 'N02BA_lag4', 'N02BA_lag8', 'N02BE_lag1', 'N02BE_lag12', 'N02BE_lag2', 'N02BE_lag8']\n",
      "\n",
      "Shapes:\n",
      "X_train_full: (223, 52)  | X_test_full: (56, 52)\n",
      "X_train_reduced: (223, 35)  | X_test_reduced: (56, 35)\n",
      "\n",
      "Null checks (should be zero):\n",
      "Full-safe train/test: 0 0\n",
      "Reduced-safe train/test: 0 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Paths\n",
    "DATA_PATH = Path(\"../data/processed/pharma_sales_features_v2_clean.csv\")\n",
    "IMP_DIR = Path(\"../results/importance\")\n",
    "\n",
    "# --- Load dataset\n",
    "df = pd.read_csv(DATA_PATH, parse_dates=[\"datum\"], index_col=\"datum\")\n",
    "\n",
    "# --- Chronological split (80/20) - same as before\n",
    "split_index = int(len(df) * 0.8)\n",
    "train = df.iloc[:split_index].copy()\n",
    "test = df.iloc[split_index:].copy()\n",
    "\n",
    "print(f\"Date range: {df.index.min()} → {df.index.max()}\")\n",
    "print(\n",
    "    f\"Train: {train.index.min()} → {train.index.max()}  |  Test: {test.index.min()} → {test.index.max()}\"\n",
    ")\n",
    "\n",
    "# --- Targets and safe features\n",
    "targets = [\"N02BE\", \"M01AB\"]\n",
    "base_cols = [\"M01AB\", \"M01AE\", \"N02BA\", \"N02BE\", \"N05B\", \"N05C\", \"R03\", \"R06\"]\n",
    "\n",
    "# Minimal calendar: drop weak flags (is_year_start/end)\n",
    "calendar_keep = [\"weekofyear\", \"month\", \"quarter\", \"year\"]\n",
    "\n",
    "# Candidate features = everything except targets\n",
    "feature_cols = [c for c in df.columns if c not in targets]\n",
    "\n",
    "# Full-safe = all lags + minimal calendar\n",
    "full_safe = [c for c in feature_cols if ((\"_lag\" in c) or (c in calendar_keep))]\n",
    "\n",
    "# Sanity checks for leakage\n",
    "assert not any(\n",
    "    c in base_cols for c in full_safe\n",
    "), \"Leakage: base columns present in features!\"\n",
    "assert not any(\"roll\" in c for c in full_safe), \"Leakage: rolling features present!\"\n",
    "\n",
    "X_train_full = train[full_safe]\n",
    "X_test_full = test[full_safe]\n",
    "\n",
    "print(\"\\n[Full-safe] Feature count:\", len(full_safe))\n",
    "print(\"Example features:\", full_safe[:10])\n",
    "\n",
    "# --- Reduced-safe: use permutation importance (if available) to select top features per target\n",
    "# Strategy:\n",
    "# - Load perm_N02BE.csv and perm_M01AB.csv from ../results/importance\n",
    "# - Take top_k from each, union them, then add minimal calendar\n",
    "top_k = 20  # you can adjust this based on desired sparsity\n",
    "\n",
    "perm_n02be_path = IMP_DIR / \"perm_N02BE.csv\"\n",
    "perm_m01ab_path = IMP_DIR / \"perm_M01AB.csv\"\n",
    "\n",
    "reduced_set = set()\n",
    "\n",
    "if perm_n02be_path.exists():\n",
    "    perm_n02be = pd.read_csv(perm_n02be_path)\n",
    "    top_n02be = (\n",
    "        perm_n02be.sort_values(\"MeanDrop\", ascending=False)\n",
    "        .head(top_k)[\"Feature\"]\n",
    "        .tolist()\n",
    "    )\n",
    "    reduced_set.update(top_n02be)\n",
    "\n",
    "if perm_m01ab_path.exists():\n",
    "    perm_m01ab = pd.read_csv(perm_m01ab_path)\n",
    "    top_m01ab = (\n",
    "        perm_m01ab.sort_values(\"MeanDrop\", ascending=False)\n",
    "        .head(top_k)[\"Feature\"]\n",
    "        .tolist()\n",
    "    )\n",
    "    reduced_set.update(top_m01ab)\n",
    "\n",
    "# Keep only features that are in full-safe (no leakage) and add minimal calendar\n",
    "reduced_safe = sorted([c for c in reduced_set if c in full_safe] + calendar_keep)\n",
    "\n",
    "# Fallback: if importance files are missing, fall back to a simple rule-based reduced set\n",
    "if len(reduced_safe) <= len(calendar_keep):\n",
    "    # Rule: keep lag1–lag4 for all ATC codes + minimal calendar\n",
    "    lag_prefixes = base_cols  # each ATC code\n",
    "    keep_rules = []\n",
    "    for code in lag_prefixes:\n",
    "        for k in [1, 2, 3, 4]:\n",
    "            keep_rules.append(f\"{code}_lag{k}\")\n",
    "    reduced_safe = sorted([c for c in keep_rules if c in df.columns] + calendar_keep)\n",
    "\n",
    "# Final sanity checks\n",
    "assert not any(c in base_cols for c in reduced_safe), \"Leakage in reduced-safe!\"\n",
    "assert not any(\n",
    "    \"roll\" in c for c in reduced_safe\n",
    "), \"Rolling feature leaked into reduced-safe!\"\n",
    "\n",
    "X_train_reduced = train[reduced_safe]\n",
    "X_test_reduced = test[reduced_safe]\n",
    "\n",
    "print(\"\\n[Reduced-safe] Feature count:\", len(reduced_safe))\n",
    "print(\"Example features:\", reduced_safe[:10])\n",
    "\n",
    "# Shapes\n",
    "print(\"\\nShapes:\")\n",
    "print(\"X_train_full:\", X_train_full.shape, \" | X_test_full:\", X_test_full.shape)\n",
    "print(\n",
    "    \"X_train_reduced:\",\n",
    "    X_train_reduced.shape,\n",
    "    \" | X_test_reduced:\",\n",
    "    X_test_reduced.shape,\n",
    ")\n",
    "\n",
    "# Quick null checks\n",
    "print(\"\\nNull checks (should be zero):\")\n",
    "print(\n",
    "    \"Full-safe train/test:\",\n",
    "    X_train_full.isna().sum().sum(),\n",
    "    X_test_full.isna().sum().sum(),\n",
    ")\n",
    "print(\n",
    "    \"Reduced-safe train/test:\",\n",
    "    X_train_reduced.isna().sum().sum(),\n",
    "    X_test_reduced.isna().sum().sum(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b546d5",
   "metadata": {},
   "source": [
    "## 2) TimeSeriesSplit Setup\n",
    "\n",
    "We apply `TimeSeriesSplit` to ensure chronological validation.  \n",
    "Unlike random CV, this method preserves temporal order — each fold uses earlier data to predict later data.\n",
    "\n",
    "Key points:\n",
    "- `n_splits = 5` (approx. 1-year per fold)\n",
    "- Expanding window strategy (no look-ahead)\n",
    "- Evaluation metric: RMSE (root mean squared error)\n",
    "\n",
    "This structure will be reused for hyperparameter tuning and model comparison.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b8b785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: train=38, val=37\n",
      "Fold 2: train=75, val=37\n",
      "Fold 3: train=112, val=37\n",
      "Fold 4: train=149, val=37\n",
      "Fold 5: train=186, val=37\n",
      "\n",
      "Fold size summary:\n",
      "[(38, 37), (75, 37), (112, 37), (149, 37), (186, 37)]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# --- Setup time series CV\n",
    "n_splits = 5\n",
    "tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "\n",
    "# --- Helper function for RMSE\n",
    "def rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "\n",
    "# --- Dry run to confirm split sizes\n",
    "fold_sizes = []\n",
    "for i, (train_idx, val_idx) in enumerate(tscv.split(X_train_full)):\n",
    "    fold_sizes.append((len(train_idx), len(val_idx)))\n",
    "    print(f\"Fold {i+1}: train={len(train_idx)}, val={len(val_idx)}\")\n",
    "\n",
    "print(\"\\nFold size summary:\")\n",
    "print(fold_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833ff468",
   "metadata": {},
   "source": [
    "## 3) Randomized Hyperparameter Search (Random Forest, full-safe)\n",
    "\n",
    "We tune RF to reduce RMSE using time-aware CV:\n",
    "- CV: TimeSeriesSplit(n_splits=5)\n",
    "- Scoring: negative RMSE (custom scorer)\n",
    "- Space: n_estimators, max_depth, min_samples_split/leaf, max_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd51edef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[N02BE] Best CV RMSE: -56.268\n",
      "[N02BE] Best params: {'random_state': 42, 'n_estimators': 400, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 16, 'bootstrap': True}\n",
      "[M01AB] Best CV RMSE: -9.621\n",
      "[M01AB] Best params: {'random_state': 42, 'n_estimators': 200, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 0.7, 'max_depth': 8, 'bootstrap': True}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "OPT_DIR = Path(\"../results/optimization\")\n",
    "OPT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "# --- custom negative RMSE scorer\n",
    "def neg_rmse(y_true, y_pred):\n",
    "    return -np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "\n",
    "rmse_scorer = make_scorer(neg_rmse, greater_is_better=False)\n",
    "\n",
    "# --- search space\n",
    "param_distributions = {\n",
    "    \"n_estimators\": [200, 300, 400, 600, 800],\n",
    "    \"max_depth\": [None, 8, 12, 16, 20],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "    \"max_features\": [\"sqrt\", 0.5, 0.7],\n",
    "    \"bootstrap\": [True],\n",
    "    \"random_state\": [42],\n",
    "}\n",
    "\n",
    "\n",
    "def run_random_search_fullsafe(target, X_train, y_train, cv, n_iter=30):\n",
    "    rf = RandomForestRegressor(n_jobs=-1, random_state=42)\n",
    "    rs = RandomizedSearchCV(\n",
    "        rf,\n",
    "        param_distributions=param_distributions,\n",
    "        n_iter=n_iter,\n",
    "        scoring=rmse_scorer,\n",
    "        cv=cv,\n",
    "        n_jobs=-1,\n",
    "        refit=True,\n",
    "        random_state=42,\n",
    "        verbose=0,\n",
    "    )\n",
    "    rs.fit(X_train, y_train)\n",
    "    # results\n",
    "    cvres = pd.DataFrame(rs.cv_results_)\n",
    "    out_csv = OPT_DIR / f\"rf_randomsearch_fullsafe_{target}.csv\"\n",
    "    cvres.to_csv(out_csv, index=False)\n",
    "    best_rmse = -rs.best_score_\n",
    "    print(f\"[{target}] Best CV RMSE: {best_rmse:.3f}\")\n",
    "    print(f\"[{target}] Best params: {rs.best_params_}\")\n",
    "    return rs, best_rmse\n",
    "\n",
    "\n",
    "# --- run for both targets on FULL-SAFE features\n",
    "rs_n02be, best_rmse_n02be = run_random_search_fullsafe(\n",
    "    \"N02BE\", X_train_full, train[\"N02BE\"], tscv\n",
    ")\n",
    "rs_m01ab, best_rmse_m01ab = run_random_search_fullsafe(\n",
    "    \"M01AB\", X_train_full, train[\"M01AB\"], tscv\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa769ce1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Target",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "MAE_before",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MAE_after",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MAE_improve(%)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RMSE_before",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RMSE_after",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RMSE_improve(%)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MAPE_before(%)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MAPE_after(%)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MAPE_improve(pp)",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "36e3cdfa-52fc-424e-9243-404dba31be57",
       "rows": [
        [
         "0",
         "N02BE",
         "35.654",
         "34.607",
         "2.936",
         "49.618",
         "51.505",
         "-3.803",
         "18.068",
         "17.894",
         "0.174"
        ],
        [
         "1",
         "M01AB",
         "6.468",
         "6.478",
         "-0.152",
         "8.598",
         "8.543",
         "0.636",
         "23.141",
         "23.226",
         "-0.085"
        ]
       ],
       "shape": {
        "columns": 10,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>MAE_before</th>\n",
       "      <th>MAE_after</th>\n",
       "      <th>MAE_improve(%)</th>\n",
       "      <th>RMSE_before</th>\n",
       "      <th>RMSE_after</th>\n",
       "      <th>RMSE_improve(%)</th>\n",
       "      <th>MAPE_before(%)</th>\n",
       "      <th>MAPE_after(%)</th>\n",
       "      <th>MAPE_improve(pp)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N02BE</td>\n",
       "      <td>35.654</td>\n",
       "      <td>34.607</td>\n",
       "      <td>2.936</td>\n",
       "      <td>49.618</td>\n",
       "      <td>51.505</td>\n",
       "      <td>-3.803</td>\n",
       "      <td>18.068</td>\n",
       "      <td>17.894</td>\n",
       "      <td>0.174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M01AB</td>\n",
       "      <td>6.468</td>\n",
       "      <td>6.478</td>\n",
       "      <td>-0.152</td>\n",
       "      <td>8.598</td>\n",
       "      <td>8.543</td>\n",
       "      <td>0.636</td>\n",
       "      <td>23.141</td>\n",
       "      <td>23.226</td>\n",
       "      <td>-0.085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Target  MAE_before  MAE_after  MAE_improve(%)  RMSE_before  RMSE_after  \\\n",
       "0  N02BE      35.654     34.607           2.936       49.618      51.505   \n",
       "1  M01AB       6.468      6.478          -0.152        8.598       8.543   \n",
       "\n",
       "   RMSE_improve(%)  MAPE_before(%)  MAPE_after(%)  MAPE_improve(pp)  \n",
       "0           -3.803          18.068         17.894             0.174  \n",
       "1            0.636          23.141         23.226            -0.085  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: ..\\results\\comparison\\rf_fullsafe_before_after.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from pathlib import Path\n",
    "\n",
    "RESULTS_DIR = Path(\"../results/comparison\")\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "def mape(y_true, y_pred):\n",
    "    eps = 1e-8\n",
    "    denom = np.clip(np.abs(y_true), eps, None)\n",
    "    return np.mean(np.abs((y_true - y_pred) / denom)) * 100\n",
    "\n",
    "\n",
    "# Best estimators from RandomizedSearchCV\n",
    "best_rf_n02be = rs_n02be.best_estimator_\n",
    "best_rf_m01ab = rs_m01ab.best_estimator_\n",
    "\n",
    "# Retrain on full train (zaten refit=True ile eğitilmiş durumda; yine de tutarlılık için fit edebiliriz)\n",
    "best_rf_n02be.fit(X_train_full, train[\"N02BE\"])\n",
    "best_rf_m01ab.fit(X_train_full, train[\"M01AB\"])\n",
    "\n",
    "# Predict on hold-out test\n",
    "yhat_n02be = best_rf_n02be.predict(X_test_full)\n",
    "yhat_m01ab = best_rf_m01ab.predict(X_test_full)\n",
    "\n",
    "# Compute metrics\n",
    "metrics_after = {\n",
    "    \"Target\": [\"N02BE\", \"M01AB\"],\n",
    "    \"MAE_after\": [\n",
    "        mean_absolute_error(test[\"N02BE\"], yhat_n02be),\n",
    "        mean_absolute_error(test[\"M01AB\"], yhat_m01ab),\n",
    "    ],\n",
    "    \"RMSE_after\": [\n",
    "        np.sqrt(mean_squared_error(test[\"N02BE\"], yhat_n02be)),\n",
    "        np.sqrt(mean_squared_error(test[\"M01AB\"], yhat_m01ab)),\n",
    "    ],\n",
    "    \"MAPE_after(%)\": [\n",
    "        mape(test[\"N02BE\"].values, yhat_n02be),\n",
    "        mape(test[\"M01AB\"].values, yhat_m01ab),\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Baseline (Day 2 RF) — sabit rakamlar\n",
    "baseline = {\n",
    "    \"N02BE\": {\"MAE\": 35.6538, \"RMSE\": 49.6175, \"MAPE(%)\": 18.0679},\n",
    "    \"M01AB\": {\"MAE\": 6.4685, \"RMSE\": 8.5978, \"MAPE(%)\": 23.1413},\n",
    "}\n",
    "\n",
    "df_after = pd.DataFrame(metrics_after)\n",
    "df_after[\"MAE_before\"] = df_after[\"Target\"].map(lambda t: baseline[t][\"MAE\"])\n",
    "df_after[\"RMSE_before\"] = df_after[\"Target\"].map(lambda t: baseline[t][\"RMSE\"])\n",
    "df_after[\"MAPE_before(%)\"] = df_after[\"Target\"].map(lambda t: baseline[t][\"MAPE(%)\"])\n",
    "\n",
    "# Improvement (% ↓)\n",
    "df_after[\"MAE_improve(%)\"] = (\n",
    "    100 * (df_after[\"MAE_before\"] - df_after[\"MAE_after\"]) / df_after[\"MAE_before\"]\n",
    ")\n",
    "df_after[\"RMSE_improve(%)\"] = (\n",
    "    100 * (df_after[\"RMSE_before\"] - df_after[\"RMSE_after\"]) / df_after[\"RMSE_before\"]\n",
    ")\n",
    "df_after[\"MAPE_improve(pp)\"] = df_after[\"MAPE_before(%)\"] - df_after[\"MAPE_after(%)\"]\n",
    "\n",
    "# Düzenli görünüm\n",
    "cols = [\n",
    "    \"Target\",\n",
    "    \"MAE_before\",\n",
    "    \"MAE_after\",\n",
    "    \"MAE_improve(%)\",\n",
    "    \"RMSE_before\",\n",
    "    \"RMSE_after\",\n",
    "    \"RMSE_improve(%)\",\n",
    "    \"MAPE_before(%)\",\n",
    "    \"MAPE_after(%)\",\n",
    "    \"MAPE_improve(pp)\",\n",
    "]\n",
    "summary_after = df_after[cols].round(3)\n",
    "display(summary_after)\n",
    "\n",
    "# Kaydet\n",
    "out_csv = RESULTS_DIR / \"rf_fullsafe_before_after.csv\"\n",
    "summary_after.to_csv(out_csv, index=False)\n",
    "print(f\"Saved: {out_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19782cb1",
   "metadata": {},
   "source": [
    "## 4) Randomized Search on Reduced-safe Feature Set\n",
    "Rationale: Use only high-contribution lags (from permutation importance) + minimal calendar to reduce noise and improve generalization, especially for peaks (RMSE).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1935f2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[N02BE] Reduced-safe best CV RMSE: -56.545\n",
      "[N02BE] Best params: {'random_state': 42, 'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'max_depth': 12, 'bootstrap': True}\n",
      "[M01AB] Reduced-safe best CV RMSE: -9.981\n",
      "[M01AB] Best params: {'random_state': 42, 'n_estimators': 200, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 0.7, 'max_depth': 16, 'bootstrap': True}\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Target",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "MAE_fullsafe_after",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RMSE_fullsafe_after",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MAPE_fullsafe_after(%)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MAE_reduced_after",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RMSE_reduced_after",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MAPE_reduced_after(%)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MAE_gain_vs_full_after(%)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "RMSE_gain_vs_full_after(%)",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "MAPE_gain_vs_full_after(pp)",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "2be8c8d3-ae9a-47d0-8245-2239e81394ac",
       "rows": [
        [
         "0",
         "N02BE",
         "34.607",
         "51.505",
         "17.894",
         "34.528",
         "50.746",
         "17.865",
         "0.228",
         "1.474",
         "0.029"
        ],
        [
         "1",
         "M01AB",
         "6.478",
         "8.543",
         "23.226",
         "6.099",
         "8.197",
         "22.139",
         "5.849",
         "4.048",
         "1.087"
        ]
       ],
       "shape": {
        "columns": 10,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>MAE_fullsafe_after</th>\n",
       "      <th>RMSE_fullsafe_after</th>\n",
       "      <th>MAPE_fullsafe_after(%)</th>\n",
       "      <th>MAE_reduced_after</th>\n",
       "      <th>RMSE_reduced_after</th>\n",
       "      <th>MAPE_reduced_after(%)</th>\n",
       "      <th>MAE_gain_vs_full_after(%)</th>\n",
       "      <th>RMSE_gain_vs_full_after(%)</th>\n",
       "      <th>MAPE_gain_vs_full_after(pp)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N02BE</td>\n",
       "      <td>34.607</td>\n",
       "      <td>51.505</td>\n",
       "      <td>17.894</td>\n",
       "      <td>34.528</td>\n",
       "      <td>50.746</td>\n",
       "      <td>17.865</td>\n",
       "      <td>0.228</td>\n",
       "      <td>1.474</td>\n",
       "      <td>0.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M01AB</td>\n",
       "      <td>6.478</td>\n",
       "      <td>8.543</td>\n",
       "      <td>23.226</td>\n",
       "      <td>6.099</td>\n",
       "      <td>8.197</td>\n",
       "      <td>22.139</td>\n",
       "      <td>5.849</td>\n",
       "      <td>4.048</td>\n",
       "      <td>1.087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Target  MAE_fullsafe_after  RMSE_fullsafe_after  MAPE_fullsafe_after(%)  \\\n",
       "0  N02BE              34.607               51.505                  17.894   \n",
       "1  M01AB               6.478                8.543                  23.226   \n",
       "\n",
       "   MAE_reduced_after  RMSE_reduced_after  MAPE_reduced_after(%)  \\\n",
       "0             34.528              50.746                 17.865   \n",
       "1              6.099               8.197                 22.139   \n",
       "\n",
       "   MAE_gain_vs_full_after(%)  RMSE_gain_vs_full_after(%)  \\\n",
       "0                      0.228                       1.474   \n",
       "1                      5.849                       4.048   \n",
       "\n",
       "   MAPE_gain_vs_full_after(pp)  \n",
       "0                        0.029  \n",
       "1                        1.087  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer, mean_squared_error, mean_absolute_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def neg_rmse(y_true, y_pred):\n",
    "    return -np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "\n",
    "rmse_scorer = make_scorer(neg_rmse, greater_is_better=False)\n",
    "\n",
    "# Slightly narrower search space to be fast\n",
    "param_dist_reduced = {\n",
    "    \"n_estimators\": [200, 300, 400, 600],\n",
    "    \"max_depth\": [None, 8, 12, 16],\n",
    "    \"min_samples_split\": [2, 5, 10],\n",
    "    \"min_samples_leaf\": [1, 2, 4],\n",
    "    \"max_features\": [\"sqrt\", 0.7],\n",
    "    \"bootstrap\": [True],\n",
    "    \"random_state\": [42],\n",
    "}\n",
    "\n",
    "\n",
    "def tune_on_reduced(target, X_train_red, y_train, cv, n_iter=25):\n",
    "    rf = RandomForestRegressor(n_jobs=-1, random_state=42)\n",
    "    rs = RandomizedSearchCV(\n",
    "        rf,\n",
    "        param_distributions=param_dist_reduced,\n",
    "        n_iter=n_iter,\n",
    "        scoring=rmse_scorer,\n",
    "        cv=cv,\n",
    "        n_jobs=-1,\n",
    "        refit=True,\n",
    "        random_state=42,\n",
    "        verbose=0,\n",
    "    )\n",
    "    rs.fit(X_train_red, y_train)\n",
    "    print(f\"[{target}] Reduced-safe best CV RMSE: {-rs.best_score_:.3f}\")\n",
    "    print(f\"[{target}] Best params: {rs.best_params_}\")\n",
    "    return rs\n",
    "\n",
    "\n",
    "# Tune for both targets on reduced features\n",
    "rs_red_n02be = tune_on_reduced(\"N02BE\", X_train_reduced, train[\"N02BE\"], tscv)\n",
    "rs_red_m01ab = tune_on_reduced(\"M01AB\", X_train_reduced, train[\"M01AB\"], tscv)\n",
    "\n",
    "# Retrain on full train (refit=True zaten var) ve testte değerlendir\n",
    "best_red_n02be = rs_red_n02be.best_estimator_.fit(X_train_reduced, train[\"N02BE\"])\n",
    "best_red_m01ab = rs_red_m01ab.best_estimator_.fit(X_train_reduced, train[\"M01AB\"])\n",
    "\n",
    "yhat_red_n02be = best_red_n02be.predict(X_test_reduced)\n",
    "yhat_red_m01ab = best_red_m01ab.predict(X_test_reduced)\n",
    "\n",
    "\n",
    "def mape(y_true, y_pred):\n",
    "    eps = 1e-8\n",
    "    denom = np.clip(np.abs(y_true), eps, None)\n",
    "    return np.mean(np.abs((y_true - y_pred) / denom)) * 100\n",
    "\n",
    "\n",
    "summary_red = pd.DataFrame(\n",
    "    {\n",
    "        \"Target\": [\"N02BE\", \"M01AB\"],\n",
    "        \"MAE_fullsafe_after\": [\n",
    "            35.654,\n",
    "            6.468,\n",
    "        ],  # will be replaced below with actual 'after' from your table if desired\n",
    "        \"RMSE_fullsafe_after\": [\n",
    "            49.618,\n",
    "            8.598,\n",
    "        ],  # placeholder baseline; compare consistently\n",
    "        \"MAPE_fullsafe_after(%)\": [\n",
    "            18.068,\n",
    "            23.141,\n",
    "        ],  # placeholder baseline; adjust as needed\n",
    "    }\n",
    ")\n",
    "\n",
    "# Gerçek karşılaştırma: \"full-safe AFTER\" yerine az önce elde ettiğin AFTER değerlerini kullanmak için:\n",
    "summary_red = pd.DataFrame(\n",
    "    {\n",
    "        \"Target\": [\"N02BE\", \"M01AB\"],\n",
    "        \"MAE_fullsafe_after\": [34.607, 6.478],\n",
    "        \"RMSE_fullsafe_after\": [51.505, 8.543],\n",
    "        \"MAPE_fullsafe_after(%)\": [17.894, 23.226],\n",
    "    }\n",
    ")\n",
    "\n",
    "summary_red[\"MAE_reduced_after\"] = [\n",
    "    mean_absolute_error(test[\"N02BE\"], yhat_red_n02be),\n",
    "    mean_absolute_error(test[\"M01AB\"], yhat_red_m01ab),\n",
    "]\n",
    "summary_red[\"RMSE_reduced_after\"] = [\n",
    "    np.sqrt(mean_squared_error(test[\"N02BE\"], yhat_red_n02be)),\n",
    "    np.sqrt(mean_squared_error(test[\"M01AB\"], yhat_red_m01ab)),\n",
    "]\n",
    "summary_red[\"MAPE_reduced_after(%)\"] = [\n",
    "    mape(test[\"N02BE\"].values, yhat_red_n02be),\n",
    "    mape(test[\"M01AB\"].values, yhat_red_m01ab),\n",
    "]\n",
    "\n",
    "# İyileşme (reduced vs full-safe AFTER)\n",
    "summary_red[\"MAE_gain_vs_full_after(%)\"] = (\n",
    "    100\n",
    "    * (summary_red[\"MAE_fullsafe_after\"] - summary_red[\"MAE_reduced_after\"])\n",
    "    / summary_red[\"MAE_fullsafe_after\"]\n",
    ")\n",
    "\n",
    "summary_red[\"RMSE_gain_vs_full_after(%)\"] = (\n",
    "    100\n",
    "    * (summary_red[\"RMSE_fullsafe_after\"] - summary_red[\"RMSE_reduced_after\"])\n",
    "    / summary_red[\"RMSE_fullsafe_after\"]\n",
    ")\n",
    "\n",
    "summary_red[\"MAPE_gain_vs_full_after(pp)\"] = (\n",
    "    summary_red[\"MAPE_fullsafe_after(%)\"] - summary_red[\"MAPE_reduced_after(%)\"]\n",
    ")\n",
    "\n",
    "summary_red = summary_red.round(3)\n",
    "display(summary_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f364755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N02BE: sMAPE=16.18%, WAPE=16.30%\n",
      "M01AB: sMAPE=17.42%, WAPE=16.64%\n"
     ]
    }
   ],
   "source": [
    "def smape(y_true, y_pred):\n",
    "    denom = (np.abs(y_true) + np.abs(y_pred)) / 2\n",
    "    eps = 1e-8\n",
    "    denom = np.clip(denom, eps, None)\n",
    "    return np.mean(np.abs(y_true - y_pred) / denom) * 100\n",
    "\n",
    "\n",
    "def wape(y_true, y_pred):\n",
    "    eps = 1e-8\n",
    "    return np.sum(np.abs(y_true - y_pred)) / np.sum(np.abs(y_true) + eps) * 100\n",
    "\n",
    "\n",
    "# calculate\n",
    "for name, y_true, y_pred in [\n",
    "    (\"N02BE\", test[\"N02BE\"], yhat_red_n02be),\n",
    "    (\"M01AB\", test[\"M01AB\"], yhat_red_m01ab),\n",
    "]:\n",
    "    print(\n",
    "        f\"{name}: sMAPE={smape(y_true, y_pred):.2f}%, WAPE={wape(y_true, y_pred):.2f}%\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
